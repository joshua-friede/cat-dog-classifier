{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IE6380_Lab_03.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshua-friede/cat-dog-classifier/blob/master/IE6380_Lab_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WX9wYpl7cxis",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run this first"
      ]
    },
    {
      "metadata": {
        "id": "e0-m5fwEcQRd",
        "colab_type": "code",
        "outputId": "9d1b338c-a07d-4652-9528-b24399437206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2043
        }
      },
      "cell_type": "code",
      "source": [
        "# 1. Download the dataset\n",
        "!wget https://user.engineering.uiowa.edu/~sbaek/files/cats_and_dogs.zip  # '!wget' command allows you to download files to your virtual machine\n",
        "!unzip -q cats_and_dogs.zip # '!unzip' is for extracting zip compressed files. '-q' is a toggle option for 'quiet' (otherwise, it will produce a long log).\n",
        "\n",
        "\n",
        "# 2. Read the dataset\n",
        "import os  # import os library for reading file paths\n",
        "import cv2 # import opencv library for image handling\n",
        "\n",
        "from tqdm import tqdm   # tqdm is a useful library for visualizing a small progress bar when you run a for loop.\n",
        "\n",
        "cat_list = ['PetImages/Cat/' + file for file in os.listdir('PetImages/Cat') if file.endswith('.jpg')]   # file paths for cat images\n",
        "dog_list = ['PetImages/Dog/' + file for file in os.listdir('PetImages/Cat') if file.endswith('.jpg')]   # file paths for dog images\n",
        "\n",
        "x = [] # empty list for storing images\n",
        "y = [] # empty list for storing image labels. we will use one-hot encoding [1, 0] = cat, [0, 1] = dog\n",
        "\n",
        "for f in tqdm(cat_list): # this is how you use tqdm\n",
        "# for f in cat_list: # this is without-tqdm version\n",
        "  img = cv2.imread(f)  # read an image from the file list\n",
        "  if img is not None:  # if image reading successful\n",
        "    x.append(cv2.resize(img, (28,28))/255.0)  # append new image to the image list. resize and normalize before to append.\n",
        "    y.append([1, 0])  # append new label to the label list\n",
        "  \n",
        "for f in tqdm(dog_list):\n",
        "  img = cv2.imread(f)\n",
        "  if img is not None:\n",
        "    x.append(cv2.resize(img, (28,28))/255.0)\n",
        "    y.append([0,1])\n",
        " \n",
        "\n",
        "# 3. Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time # this is for generating random seed\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=int(time.time()))\n",
        "\n",
        "print(len(x), len(train_x), len(test_x))\n",
        "\n",
        "\n",
        "\n",
        "# 4. Build a model \n",
        "import tensorflow as tf\n",
        "\n",
        "# placeholder for the dataset\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
        "Y = tf.placeholder(tf.float32, [None, 2])\n",
        "\n",
        "# model parameters\n",
        "W = tf.Variable(tf.zeros([2352, 2]))\n",
        "b = tf.Variable(tf.zeros([2]))\n",
        "\n",
        "# model ops\n",
        "Z = tf.matmul(tf.reshape(X, [-1, 2352]), W) + b\n",
        "f = tf.divide(tf.exp(Z), tf.reduce_sum(tf.exp(Z)))\n",
        "# f = tf.nn.softmax(Z)  # tensorflow provides softmax function for your convenience\n",
        "\n",
        "\n",
        "# 5. Design an optimizer\n",
        "e = -tf.reduce_sum(Y * tf.log(f)) # cross entropy loss\n",
        "optimizer = tf.train.AdamOptimizer(0.01).minimize(e) # adam optimizer\n",
        "\n",
        "# accuracy. (cross entropy can be less intuitive. a good practice would be to trace accuracy alongside cross entropy\n",
        "is_correct = tf.equal(tf.argmax(f,1), tf.argmax(Y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "\n",
        "# 6. Train\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer()) # we have variables W and b which need to be initialized\n",
        "  \n",
        "  for i in range(100): # for some fixed number of iterations\n",
        "    sess.run(optimizer, feed_dict={X: train_x, Y: train_y}) # run one step of iteration\n",
        "    acc, ce = sess.run([accuracy, e], feed_dict={X: train_x, Y: train_y}) # evaluate accuracy and cross entropy error\n",
        "    print(i, acc, ce) # print them\n",
        "    \n",
        "  acc, ce = sess.run([accuracy, e], feed_dict={X: test_x, Y: test_y}) # when the iteration is over, test the model against the test dataset\n",
        "  print('TEST', acc, ce)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-14 18:47:06--  https://user.engineering.uiowa.edu/~sbaek/files/cats_and_dogs.zip\n",
            "Resolving user.engineering.uiowa.edu (user.engineering.uiowa.edu)... 128.255.17.187\n",
            "Connecting to user.engineering.uiowa.edu (user.engineering.uiowa.edu)|128.255.17.187|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs.zip’\n",
            "\n",
            "cats_and_dogs.zip   100%[===================>] 786.68M  10.3MB/s    in 2m 22s  \n",
            "\n",
            "2019-02-14 18:49:34 (5.52 MB/s) - ‘cats_and_dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12500/12500 [00:27<00:00, 460.15it/s]\n",
            "100%|██████████| 12500/12500 [00:28<00:00, 442.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24946 17462 7484\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "0 0.5021189 288781.5\n",
            "1 0.4944451 234589.12\n",
            "2 0.49811018 233657.78\n",
            "3 0.53951436 192459.64\n",
            "4 0.50166076 221076.34\n",
            "5 0.5010881 224728.9\n",
            "6 0.5052113 198849.66\n",
            "7 0.49902645 204129.25\n",
            "8 0.4989692 218371.47\n",
            "9 0.5000573 202360.88\n",
            "10 0.5256557 191567.34\n",
            "11 0.50223345 205582.47\n",
            "12 0.5036651 197842.03\n",
            "13 0.50080174 184905.0\n",
            "14 0.49891192 197510.1\n",
            "15 0.49954185 190196.38\n",
            "16 0.50641394 186062.9\n",
            "17 0.5014889 193427.38\n",
            "18 0.5397434 183715.31\n",
            "19 0.49868286 190093.22\n",
            "20 0.49816746 189757.22\n",
            "21 0.5646547 183366.08\n",
            "22 0.5087046 189825.78\n",
            "23 0.5513687 184423.19\n",
            "24 0.49937007 186123.69\n",
            "25 0.49816746 187347.9\n",
            "26 0.5805177 182808.61\n",
            "27 0.51053715 186705.72\n",
            "28 0.5341885 184037.33\n",
            "29 0.5134578 183937.9\n",
            "30 0.5026343 185405.56\n",
            "31 0.5938037 182405.0\n",
            "32 0.5080747 184927.7\n",
            "33 0.5418623 183035.11\n",
            "34 0.5174665 183707.28\n",
            "35 0.5167793 183835.81\n",
            "36 0.55217046 182744.7\n",
            "37 0.51706564 184002.1\n",
            "38 0.58395374 182315.72\n",
            "39 0.517352 183720.22\n",
            "40 0.58859235 182260.1\n",
            "41 0.52771735 183261.95\n",
            "42 0.5810331 182357.11\n",
            "43 0.53447485 182866.94\n",
            "44 0.55646545 182501.89\n",
            "45 0.56803346 182585.25\n",
            "46 0.5683198 182622.62\n",
            "47 0.5719849 182407.4\n",
            "48 0.55234224 182657.53\n",
            "49 0.5946627 182282.19\n",
            "50 0.57272935 182601.27\n",
            "51 0.5964953 182183.28\n",
            "52 0.5592716 182503.47\n",
            "53 0.60743326 182120.56\n",
            "54 0.578227 182411.5\n",
            "55 0.6072615 182097.61\n",
            "56 0.5719849 182348.66\n",
            "57 0.6082923 182100.9\n",
            "58 0.5868171 182296.12\n",
            "59 0.60680336 182107.06\n",
            "60 0.58487 182243.27\n",
            "61 0.60852134 182107.88\n",
            "62 0.59615165 182188.69\n",
            "63 0.6044554 182104.47\n",
            "64 0.59666705 182140.02\n",
            "65 0.60800594 182103.05\n",
            "66 0.60886496 182099.94\n",
            "67 0.6023365 182103.47\n",
            "68 0.61046845 182068.42\n",
            "69 0.6084641 182103.38\n",
            "70 0.61567974 182046.14\n",
            "71 0.60399723 182098.61\n",
            "72 0.61407626 182033.92\n",
            "73 0.61006755 182084.58\n",
            "74 0.6141908 182031.31\n",
            "75 0.61006755 182061.2\n",
            "76 0.6167678 182034.66\n",
            "77 0.61705416 182035.06\n",
            "78 0.6127591 182038.23\n",
            "79 0.617226 182015.89\n",
            "80 0.6149353 182036.47\n",
            "81 0.61923033 182008.19\n",
            "82 0.6143626 182026.75\n",
            "83 0.62026113 182008.5\n",
            "84 0.6195167 182011.27\n",
            "85 0.6173978 182009.66\n",
            "86 0.6188294 181997.0\n",
            "87 0.61900127 182006.06\n",
            "88 0.61905855 181990.3\n",
            "89 0.618314 181996.66\n",
            "90 0.6213492 181990.23\n",
            "91 0.62077653 181985.72\n",
            "92 0.6194594 181989.3\n",
            "93 0.6208338 181978.97\n",
            "94 0.6219219 181982.34\n",
            "95 0.6204329 181976.86\n",
            "96 0.62180734 181972.84\n",
            "97 0.62272364 181974.16\n",
            "98 0.6219792 181966.9\n",
            "99 0.6222655 181967.62\n",
            "TEST 0.59807587 71720.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o-LPzQqXWE1f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab"
      ]
    },
    {
      "metadata": {
        "id": "Vw2sS7c-Y7eC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yb = []\n",
        "for i in range(len(y)):  # y[i] = [1,0] or [0,1]\n",
        "  yb.append( [ y[i][0] ] )\n",
        "  \n",
        "train_x, test_x, train_yb, test_yb = train_test_split(x, yb, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxyTFrEnWNyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Step 1. Build Perceptron\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([28*28*3, 1], stddev=0.01))\n",
        "b = tf.Variable(tf.random_normal([1], stddev=0.01))\n",
        "\n",
        "reshaped_X = tf.reshape(X, [-1, 28*28*3])\n",
        "Z = tf.matmul(reshaped_X, W) + b\n",
        "f = 0.5*tf.sign(Z) + 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Z-BRx2cZx1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Step 2. Loss and Optimizer\n",
        "delta = Y - f\n",
        "loss = tf.reduce_mean( tf.square(delta) ) # MSE\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
        "lr = 0.001\n",
        "Xd = tf.transpose( tf.multiply(reshaped_X, delta) ) # rX = [N, d] del = [N, 1]\n",
        "dW = tf.reduce_sum(Xd, axis=1, keepdims=True) # Xd = [d, N] --> [d, 1]\n",
        "\n",
        "db = tf.reduce_sum(delta, axis=0)\n",
        "\n",
        "Wupdate = tf.assign_sub(W, lr*dW)  # assign_sub  -=\n",
        "bupdate = b.assign_sub(lr*db)\n",
        "\n",
        "optimizer = [Wupdate, bupdate]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8aJ1gV1uaXxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Step 3. Train\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for i in range(10):\n",
        "    sess.run(optimizer, feed_dict={X: train_x, Y: train_yb})\n",
        "    mse = sess.run(loss, feed_dict={X: train_x, Y: train_yb})\n",
        "    print(i, mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qliwd_BlWPZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([28*28*3,1], stddev=0.01))\n",
        "b = tf.Variable(tf.random_normal([1], stddev=0.01))\n",
        "\n",
        "reshaped_X = tf.reshape(X, [-1, 28*28*3]) - 0.5 # normalize\n",
        "Z = tf.matmul(reshaped_X, W) + b\n",
        "\n",
        "f = tf.sigmoid(Z)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AH_p3xoYF8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and Optmizer\n",
        "\n",
        "delta = Y - f\n",
        "loss = tf.reduce_mean( tf.square(delta) )\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsR4NgzZYIOh",
        "colab_type": "code",
        "outputId": "8cb8d36c-2428-41aa-8fa4-ed353cc8ec3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for i in range(100):\n",
        "    sess.run(optimizer, feed_dict={X: train_x, Y: train_yb})\n",
        "    loss_val = sess.run(loss, feed_dict={X:train_x, Y: train_yb})\n",
        "    print(loss_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.31875548\n",
            "0.27743363\n",
            "0.27150232\n",
            "0.25736573\n",
            "0.2662277\n",
            "0.26318577\n",
            "0.24641636\n",
            "0.24734837\n",
            "0.24709973\n",
            "0.2417731\n",
            "0.24456102\n",
            "0.24410036\n",
            "0.23948112\n",
            "0.23873833\n",
            "0.23621085\n",
            "0.23611897\n",
            "0.23814051\n",
            "0.23452476\n",
            "0.23099968\n",
            "0.23275295\n",
            "0.23352647\n",
            "0.23320794\n",
            "0.23138033\n",
            "0.2285933\n",
            "0.2295837\n",
            "0.2305431\n",
            "0.22845326\n",
            "0.22733563\n",
            "0.22700587\n",
            "0.22736008\n",
            "0.22746664\n",
            "0.22585736\n",
            "0.22544742\n",
            "0.22549307\n",
            "0.22502144\n",
            "0.22486238\n",
            "0.22420205\n",
            "0.22403009\n",
            "0.22393534\n",
            "0.2235688\n",
            "0.22343363\n",
            "0.22281215\n",
            "0.22256453\n",
            "0.22254048\n",
            "0.22227788\n",
            "0.2219617\n",
            "0.22160073\n",
            "0.22166015\n",
            "0.22140855\n",
            "0.22100155\n",
            "0.22080438\n",
            "0.22070436\n",
            "0.22056493\n",
            "0.22021887\n",
            "0.22009693\n",
            "0.21996216\n",
            "0.21977551\n",
            "0.21956275\n",
            "0.21939747\n",
            "0.21928771\n",
            "0.21910915\n",
            "0.2189728\n",
            "0.2187905\n",
            "0.21866496\n",
            "0.2185201\n",
            "0.21837844\n",
            "0.21822092\n",
            "0.21810675\n",
            "0.21799496\n",
            "0.21784231\n",
            "0.2177125\n",
            "0.21760002\n",
            "0.21748523\n",
            "0.21734287\n",
            "0.21723974\n",
            "0.21713132\n",
            "0.21701825\n",
            "0.21689838\n",
            "0.21680114\n",
            "0.21669303\n",
            "0.21658936\n",
            "0.21648501\n",
            "0.21638882\n",
            "0.21628904\n",
            "0.21619242\n",
            "0.21609367\n",
            "0.21600278\n",
            "0.21591152\n",
            "0.21581942\n",
            "0.21572919\n",
            "0.21564469\n",
            "0.21555604\n",
            "0.21546914\n",
            "0.2153865\n",
            "0.21530506\n",
            "0.21522152\n",
            "0.21514228\n",
            "0.21506363\n",
            "0.21498519\n",
            "0.21490745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aZxrUqlRc_hS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras"
      ]
    },
    {
      "metadata": {
        "id": "iIAoQqLxeifA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rp1xl0Kdcwmk",
        "colab_type": "code",
        "outputId": "28e51cc1-d062-472c-88dc-69f57c8fe6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add( keras.layers.Flatten( input_shape=(28,28,3) ) )\n",
        "model.add( keras.layers.Dense(100, activation='sigmoid') )\n",
        "model.add( keras.layers.Dense(1, activation='sigmoid') )\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 2352)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               235300    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 235,401\n",
            "Trainable params: 235,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pnDKx0z3eSkw",
        "colab_type": "code",
        "outputId": "386f5d03-5129-4171-82de-26776d8b7a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1407
        }
      },
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'mae'])\n",
        "\n",
        "model.fit( np.array(train_x), np.array(train_yb), epochs=100, validation_split=0.3, callbacks=[tensorboard] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12223 samples, validate on 5239 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_3:0\", shape=(), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-20c7675f361d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_yb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0mtraining_distributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(x, value)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_3:0\", shape=(), dtype=float32) is not an element of this graph."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mW3YrP_rhI8v",
        "colab_type": "code",
        "outputId": "077c9ecf-9074-4ec1-adcb-a240fb8fd1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# This is the TensorBoard setup routine from Lab01\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"log/{}\".format(time.time()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-14 19:40:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.71.139.107, 52.54.84.112, 52.45.111.123, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.71.139.107|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  9.44MB/s    in 0.5s    \n",
            "\n",
            "2019-02-14 19:40:29 (9.44 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://f18ad8bc.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}